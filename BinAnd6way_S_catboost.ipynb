{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "This notebook contains\n",
    "- training of catboost decision tree models for binary classification \n",
    "- training of catboost decision tree models for 6-way classification\n",
    "\n",
    "Libraries used\n",
    "- keras for tokenizer\n",
    "- catboost for decision tree model\n",
    "\n",
    "## Model Description\n",
    "### Binary - cat_model\n",
    "- tokenize the text files of the statements\n",
    "- pass through the catboost decision tree model with a binary CatBoostClassifier\n",
    "\n",
    "### 6 way - cat_model_6\n",
    "- tokenize the text files of the statements\n",
    "- pass through the catboost decision tree model with a 6 class CatBoostClassifier\n",
    "\n",
    "## Result\n",
    "### Binary - cat_model\n",
    "- Test accuracy - 56.43%\n",
    " \n",
    "### 6 way - cat_model_6\n",
    "- Test accuracy - 21.23%\n",
    "\n",
    "## Model file\n",
    "### Binary - cat_model\n",
    "- cat_model\n",
    "\n",
    "### 6 way - cat_model_6\n",
    "- cat_model_6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = \"dataset\"\n",
    "\n",
    "train_data_file = os.path.join(dataset_dir, \"train2.tsv\")\n",
    "test_data_file = os.path.join(dataset_dir, \"test2.tsv\")\n",
    "val_data_file = os.path.join(dataset_dir, \"val2.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column names are taken from the readme.md of the LIAR-PLUS github repo -\n",
    "# link to repo - https://github.com/Tariq60/LIAR-PLUS\n",
    "\n",
    "col_names = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"speaker_job\", \"state_info\", \"party\", \\\n",
    "             \"barely_true\", \"false\", \"half_true\", \"mostly_true\", \"pants_on_fire\", \"context\", \"ex_just\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_data_file, sep = '\\t', header = None, names = col_names,)# na_values = [\"NaN\"], na_filter = True)\n",
    "test_data = pd.read_csv(test_data_file, sep = '\\t', header = None, names = col_names)\n",
    "val_data = pd.read_csv(val_data_file, sep = '\\t', header = None, names = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_seq = 1000\n",
    "max_no_of_words = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing the statements\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_no_of_words)\n",
    "\n",
    "tokenizer.fit_on_texts(list(train_data[\"statement\"]))\n",
    "\n",
    "train_sequences = tokenizer.texts_to_sequences(list(train_data[\"statement\"]))\n",
    "val_sequences = tokenizer.texts_to_sequences(list(val_data[\"statement\"]))\n",
    "test_sequences = tokenizer.texts_to_sequences(list(test_data[\"statement\"]))\n",
    "\n",
    "train_seq = np.array(pad_sequences(train_sequences, maxlen = max_len_seq))\n",
    "val_seq = np.array(pad_sequences(val_sequences, maxlen = max_len_seq))\n",
    "test_seq = np.array(pad_sequences(test_sequences, maxlen = max_len_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_val = {\"pants-fire\":0, \"false\":0, \"barely-true\":0, \"half-true\":1, \"mostly-true\":1, \"true\":1}\n",
    "train_tf = np.array(list(map(lambda l: tf_val[l], list(train_data[\"label\"]))))\n",
    "train_cat_tf = to_categorical(train_tf)\n",
    "\n",
    "val_tf = np.array(list(map(lambda l: tf_val[l], list(val_data[\"label\"]))))\n",
    "val_cat_tf = to_categorical(val_tf)\n",
    "\n",
    "test_tf = np.array(list(map(lambda l: tf_val[l], list(test_data[\"label\"]))))\n",
    "test_cat_tf = to_categorical(test_tf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cat_model = CatBoostClassifier(loss_function = 'CrossEntropy')\n",
    "cat_model.fit(train_seq, train_tf, eval_set = (val_seq, val_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model.score(test_seq, test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = cat_model.predict(test_seq)\n",
    "\n",
    "print(pred[:20])\n",
    "print(test_tf[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model.save_model(\"cat_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "six_val = {\"pants-fire\":0, \"false\":1, \"barely-true\":2, \"half-true\":3, \"mostly-true\":4, \"true\":5}\n",
    "rev_six_val = dict(map(reversed, six_val.items()))\n",
    "\n",
    "train_6 = np.array(list(map(lambda l: six_val[l], list(train_data[\"label\"]))))\n",
    "train_cat_6 = to_categorical(train_6)\n",
    "\n",
    "val_6 = np.array(list(map(lambda l: six_val[l], list(val_data[\"label\"]))))\n",
    "val_cat_6 = to_categorical(val_6)\n",
    "\n",
    "test_6 = np.array(list(map(lambda l: six_val[l], list(test_data[\"label\"]))))\n",
    "test_cat_6 = to_categorical(test_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model_6 = CatBoostClassifier(loss_function = 'MultiClass')\n",
    "cat_model_6.fit(train_seq, train_6, eval_set = (val_seq, val_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model_6.score(test_seq, test_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_6 = cat_model_6.predict(test_seq)\n",
    "\n",
    "print(pred_6[:20])\n",
    "print(test_6[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model_6.save_model(\"cat_model_6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
